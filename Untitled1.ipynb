{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPztbIDoFMDZXiKHYKlbYWq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeerBay/Deep-Learning-Julia/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium ale_py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1AvlxMmM2b-",
        "outputId": "61536209-e066-4900-cb8d-ffb4cd3b14bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: ale_py in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "import gymnasium as gym\n",
        "from gymnasium.wrappers import FrameStackObservation, AtariPreprocessing, RecordVideo\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "import os\n",
        "import ale_py\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Device selection\n",
        "device_name = \"gpu\"  # Set to \"cpu\" or \"gpu\" as needed\n",
        "if device_name == \"gpu\" and tf.config.list_physical_devices('GPU'):\n",
        "    device = \"/GPU:0\"\n",
        "else:\n",
        "    device = \"/CPU:0\"\n",
        "device\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "# Setup Atari environment\n",
        "env = gym.make(\"SpaceInvadersNoFrameskip-v4\", render_mode=\"rgb_array\")  # Use rgb_array for recording\n",
        "\n",
        "# Apply Atari preprocessing\n",
        "env = AtariPreprocessing(env, frame_skip=4, grayscale_obs=True, scale_obs=True)\n",
        "\n",
        "# Apply FrameStackObservation to stack 4 frames\n",
        "env = FrameStackObservation(env, stack_size=4)  # Use stack_size parameter for frame stacking\n",
        "\n",
        "# Record videos every 20th episode\n",
        "trigger = lambda t: t % 20 == 0  # Video every 20th episode\n",
        "env = RecordVideo(env, video_folder=\"./videos\", episode_trigger=trigger, disable_logger=True)\n",
        "\n",
        "# Test the setup\n",
        "observation, info = env.reset()\n",
        "print(f\"Initial observation shape: {observation.shape}\")\n",
        "\n",
        "# Get the number of actions\n",
        "num_actions = env.action_space.n\n",
        "print(f\"Number of actions: {num_actions}\")\n",
        "# List all action meanings\n",
        "action_meanings = env.unwrapped.get_action_meanings()\n",
        "print(\"Actions and their meanings:\", action_meanings)\n",
        "\n",
        "# Get the number of actions\n",
        "num_actions = env.action_space.n\n",
        "print(f\"Number of actions: {num_actions}\")\n",
        "# List all action meanings\n",
        "action_meanings = env.unwrapped.get_action_meanings()\n",
        "print(\"Actions and their meanings:\", action_meanings)\n",
        "\n",
        "epsilon_decay_frames = 1000000  # Adjust this value if needed\n",
        "batch_size = 32\n",
        "max_steps_per_episode = 10000\n",
        "max_episodes = 10000 # Update this\n",
        "max_frames = 1e7\n",
        "\n",
        "# Replay buffer parameters\n",
        "# NOTE: The Deepmind paper suggests 1000000 however this causes memory issues\n",
        "max_memory_length = 100000\n",
        "\n",
        "# Function to create the Q-network model\n",
        "def create_q_model(input_shape=(84, 84, 4), num_actions=6):\n",
        "    return tf.keras.Sequential(\n",
        "        [\n",
        "            layers.Input(shape=input_shape),\n",
        "            layers.Conv2D(32, kernel_size=8, strides=4, activation=\"relu\"),\n",
        "            layers.Conv2D(64, kernel_size=4, strides=2, activation=\"relu\"),\n",
        "            layers.Conv2D(64, kernel_size=3, strides=1, activation=\"relu\"),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(512, activation=\"relu\"),\n",
        "            layers.Dense(num_actions, activation=\"linear\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# Hyperparameters\n",
        "input_shape = (84, 84, 4)\n",
        "num_actions = 6\n",
        "gamma = 0.99  # Discount factor\n",
        "batch_size = 32\n",
        "epsilon = 1.0\n",
        "epsilon_min = 0.1\n",
        "epsilon_interval = (epsilon - epsilon_min)  # Range of epsilon decay\n",
        "epsilon_random_frames = 1000\n",
        "epsilon_greedy_frames = 1000000\n",
        "max_steps_per_episode = 10000\n",
        "update_after_actions = 4\n",
        "update_target_network = 10000\n",
        "tau = 0.005  # Soft update factor\n",
        "# Using huber loss for stability (specifically for Adam)\n",
        "loss_function = keras.losses.Huber()\n",
        "\n",
        "# Environment and Replay Buffer\n",
        "replay_buffer = deque(maxlen=100000)\n",
        "frame_count = 0\n",
        "episode_count = 0\n",
        "episode_reward_history = []\n",
        "best_running_reward = -float(\"inf\")\n",
        "running_reward = 0\n",
        "\n",
        "# Models and Optimizer\n",
        "model = create_q_model(input_shape, num_actions)\n",
        "model_target = create_q_model(input_shape, num_actions)\n",
        "model_target.set_weights(model.get_weights())  # Synchronize weights initially\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
        "\n",
        "# Create directory for saving models\n",
        "save_dir = \"models\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Training loop\n",
        "with tf.device(\"/gpu:0\"):  # Adjust device as needed\n",
        "    print(f\"Using device: /gpu:0\")\n",
        "    while True:\n",
        "        # Reset environment\n",
        "        observation, _ = env.reset()\n",
        "        state = np.array(observation, dtype=np.float32) / 255.0  # Normalize and preprocess state\n",
        "        state = np.transpose(state, (1, 2, 0))  # Ensure (84, 84, 4)\n",
        "        episode_reward = 0\n",
        "\n",
        "        for timestep in range(1, max_steps_per_episode + 1):\n",
        "            frame_count += 1\n",
        "\n",
        "            # Epsilon-greedy action selection\n",
        "            if frame_count < epsilon_random_frames or np.random.rand() < epsilon:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                state_tensor = tf.convert_to_tensor(state, dtype=tf.float32)\n",
        "                state_tensor = tf.expand_dims(state_tensor, 0)  # Add batch dimension\n",
        "                action_probs = model(state_tensor, training=False)\n",
        "                action = tf.argmax(action_probs[0]).numpy()\n",
        "\n",
        "            # Decay epsilon\n",
        "            epsilon -= epsilon_interval / epsilon_greedy_frames\n",
        "            epsilon = max(epsilon, epsilon_min)\n",
        "\n",
        "            # Environment step\n",
        "            state_next, reward, done, _, _ = env.step(action)\n",
        "            state_next = np.array(state_next, dtype=np.float32) / 255.0\n",
        "            state_next = np.transpose(state_next, (1, 2, 0))  # Ensure (84, 84, 4)\n",
        "            episode_reward += reward\n",
        "\n",
        "            # Store transition in replay buffer\n",
        "            replay_buffer.append((state, action, reward, state_next, done))\n",
        "            state = state_next\n",
        "\n",
        "            # Training\n",
        "            if frame_count % update_after_actions == 0 and len(replay_buffer) >= batch_size:\n",
        "                # Sample batch from replay buffer\n",
        "                batch = random.sample(replay_buffer, batch_size)\n",
        "                states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "                # Convert to tensors\n",
        "                state_sample = tf.convert_to_tensor(states, dtype=tf.float32)  # (batch_size, 84, 84, 4)\n",
        "                next_state_sample = tf.convert_to_tensor(next_states, dtype=tf.float32)  # (batch_size, 84, 84, 4)\n",
        "\n",
        "                action_sample = tf.convert_to_tensor(actions, dtype=tf.int32)\n",
        "                reward_sample = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
        "                done_sample = tf.convert_to_tensor(dones, dtype=tf.float32)\n",
        "\n",
        "                # Compute target Q-values\n",
        "                future_rewards = model_target(next_state_sample, training=False)\n",
        "                updated_q_values = reward_sample + gamma * tf.reduce_max(future_rewards, axis=1) * (1 - done_sample)\n",
        "\n",
        "                # Train model\n",
        "                with tf.GradientTape() as tape:\n",
        "                    q_values = model(state_sample)\n",
        "                    q_action = tf.reduce_sum(tf.one_hot(action_sample, num_actions) * q_values, axis=1)\n",
        "                    loss = tf.keras.losses.Huber()(updated_q_values, q_action)\n",
        "\n",
        "                grads = tape.gradient(loss, model.trainable_variables)\n",
        "                optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "            # Update target network\n",
        "            if frame_count % update_target_network == 0:\n",
        "                model_target.set_weights(model.get_weights())\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # Log rewards and progress\n",
        "        episode_reward_history.append(episode_reward)\n",
        "        running_reward = np.mean(episode_reward_history[-100:])\n",
        "        episode_count += 1\n",
        "\n",
        "        if running_reward > best_running_reward:\n",
        "            best_running_reward = running_reward\n",
        "            model.save(f\"{save_dir}/best_model_episode_{episode_count}.keras\")\n",
        "\n",
        "        if episode_count % 10 == 0:\n",
        "            print(f\"Episode: {episode_count}, Running Reward: {running_reward:.2f}, Epsilon: {epsilon:.2f}\")\n",
        "            print(f\"Episod {episode_count} finished. Totalamount of frames: {frame_count}\")\n",
        "\n",
        "\n",
        "        if running_reward > 10000 or frame_count >= 50000000:\n",
        "            print(f\"Training complete after {episode_count} episodes and {frame_count} frames.\")\n",
        "            model.save(f\"{save_dir}/final_model.keras\")\n",
        "            break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "FzxoNo6_gvfL",
        "outputId": "c80c3a5c-ead4-4249-b7f3-33ac23758485"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: /gpu:0\n",
            "Episode: 10, Running Reward: 163.50, Epsilon: 1.00\n",
            "Episod 10 finished. Totalamount of frames: 4910\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-af663818a0eb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# Update target network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;31m# Apply gradient updates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0;31m# Apply variable constraints after applying gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36m_backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;31m# Run udpate step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             self._backend_update_step(\n\u001b[0m\u001b[1;32m    420\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36m_backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_reduce_sum_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_tf_update_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribute_lib.get_replica_context().merge_call(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36m_distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             distribution.extended.update(\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3003\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   3004\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3005\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3007\u001b[0m       return self._replica_ctx_update(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4073\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4074\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4075\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4079\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4081\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4082\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4083\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    130\u001b[0m     ):\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py\u001b[0m in \u001b[0;36mupdate_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         self.assign_add(\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         )\n\u001b[1;32m    135\u001b[0m         self.assign_add(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/numpy.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m   5512\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5513\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5514\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/sparse.py\u001b[0m in \u001b[0;36msparse_wrapper\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    625\u001b[0m                 )\n\u001b[1;32m    626\u001b[0m         \u001b[0;31m# Default case, no SparseTensor and no IndexedSlices.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/numpy.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    496\u001b[0m     )\n\u001b[1;32m    497\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m   \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m    162\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;31m# preferred_dtype = preferred_dtype or dtype_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   return tensor_conversion_registry.convert(\n\u001b[0m\u001b[1;32m    172\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    250\u001b[0m               \u001b[0;34mf\"{base_type} returned non-Tensor: {ret!r}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               name=name))\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m       raise RuntimeError(\n\u001b[1;32m    254\u001b[0m           _add_error_prefix(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mis_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0mthis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDType\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \"\"\"\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     return self._type_enum in (other.as_datatype_enum,\n\u001b[1;32m    214\u001b[0m                                other.base_dtype.as_datatype_enum)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(device):  # Ensures all TensorFlow operations are executed on the selected device\n",
        "    print(f\"Using device: {device}\")\n",
        "    while True:\n",
        "        # Reset environment\n",
        "        observation, _ = env.reset()\n",
        "        state = np.array(observation)  # Preprocessed state\n",
        "        #print(\"State shape:\", state.shape)  # Debugging to verify shape\n",
        "        episode_reward = 0\n",
        "\n",
        "        for timestep in range(1, max_steps_per_episode):\n",
        "            frame_count += 1\n",
        "\n",
        "            # Epsilon-greedy action selection\n",
        "            if frame_count < epsilon_random_frames or tf.random.uniform((1,)) < epsilon:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                # Ensure state is in the correct format: (batch_size, height, width, channels)\n",
        "                state_tensor = keras.ops.convert_to_tensor(state)\n",
        "                state_tensor = keras.ops.expand_dims(state_tensor, 0)\n",
        "                action_probs = model(state_tensor, training=False)\n",
        "                action = keras.ops.argmax(action_probs[0]).numpy()\n",
        "\n",
        "            # Decay probability of taking random action\n",
        "            epsilon -= epsilon_interval / epsilon_greedy_frames\n",
        "            epsilon = max(epsilon, epsilon_min)\n",
        "\n",
        "            # Step in the environment\n",
        "            state_next, reward, done, _, _ = env.step(action)\n",
        "            state_next = np.array(state_next)  # Preprocessed next state\n",
        "            episode_reward += reward\n",
        "\n",
        "            # Store transition in replay buffer\n",
        "            replay_buffer.append((state, action, reward, state_next, done))\n",
        "            state = state_next  # Update state\n",
        "\n",
        "            # Train the model\n",
        "            if frame_count % update_after_actions == 0 and len(replay_buffer) >= batch_size:\n",
        "                # Sample a batch from replay buffer\n",
        "                batch = random.sample(replay_buffer, batch_size)\n",
        "                states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "                # Convert to tensors\n",
        "                state_sample = tf.stack(states, axis=0)  # Combine into a single tensor\n",
        "                print(\"state_sample shape before transpose:\", state_sample.shape)\n",
        "\n",
        "                # Transpose to (batch_size, 84, 84, 4)\n",
        "                state_sample = tf.transpose(state_sample, perm=[0, 2, 3, 1])  # Correct permutation\n",
        "                print(\"state_sample shape after transpose:\", state_sample.shape)\n",
        "\n",
        "                state_sample = tf.cast(state_sample, dtype=tf.float32)\n",
        "\n",
        "\n",
        "                next_state_sample = tf.stack(next_states, axis=0)  # Result: (batch_size, 4, 84, 84)\n",
        "                print(\"next_state_sample shape before transpose:\", next_state_sample.shape)\n",
        "                next_state_sample = tf.transpose(next_state_sample, perm=[0, 2, 3, 1])  # Rearrange to (batch_size, 84, 84, 4)\n",
        "                print(\"next_state_sample shape after transpose:\", next_state_sample.shape)\n",
        "                next_state_sample = tf.cast(next_state_sample, dtype=tf.float32)\n",
        "\n",
        "                action_sample = tf.convert_to_tensor(actions, dtype=tf.int32)\n",
        "                reward_sample = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
        "                done_sample = tf.convert_to_tensor(dones, dtype=tf.float32)\n",
        "\n",
        "                # Debugging final shapes before passing to the model\n",
        "                print(\"state_sample final shape:\", state_sample.shape)  # Expected: (batch_size, 84, 84, 4)\n",
        "                print(\"next_state_sample final shape:\", next_state_sample.shape)  # Expected: (batch_size, 84, 84, 4)\n",
        "                print(\"action_sample final shape:\", action_sample.shape)  # Expected: (batch_size,)\n",
        "\n",
        "                # Compute target Q-values\n",
        "                future_rewards = model_target(next_state_sample)\n",
        "                updated_q_values = reward_sample + gamma * tf.reduce_max(future_rewards, axis=1) * (1 - done_sample)\n",
        "\n",
        "                # Masked loss\n",
        "                with tf.GradientTape() as tape:\n",
        "                    q_values = model(state_sample)\n",
        "                    q_action = tf.reduce_sum(tf.one_hot(action_sample, num_actions) * q_values, axis=1)\n",
        "                    loss = loss_function(updated_q_values, q_action)\n",
        "\n",
        "                # Backpropagation\n",
        "                grads = tape.gradient(loss, model.trainable_variables)\n",
        "                print(\"Gradient shapes:\", [g.shape for g in grads if g is not None])\n",
        "                optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "            # Update target network\n",
        "            if frame_count % update_target_network == 0:\n",
        "                model_target.set_weights([\n",
        "                    tau * w + (1 - tau) * tw\n",
        "                    for w, tw in zip(model.get_weights(), model_target.get_weights())\n",
        "                ])\n",
        "\n",
        "            # End episode if done\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # Update running reward and history\n",
        "        episode_reward_history.append(episode_reward)\n",
        "        running_reward = np.mean(episode_reward_history)\n",
        "        episode_count += 1\n",
        "        # Update progress bar\n",
        "        episode_bar.update(1)  # Increment the progress bar by one episode\n",
        "        episode_bar.set_postfix(running_reward=f\"{running_reward:.2f}\", epsilon=f\"{epsilon:.2f}\")\n",
        "\n",
        "        # Check if the model should be saved\n",
        "        if running_reward > best_running_reward:\n",
        "            best_running_reward = running_reward\n",
        "\n",
        "            # Remove the last saved model if it exists\n",
        "            if last_saved_model and os.path.exists(last_saved_model):\n",
        "                os.remove(last_saved_model)\n",
        "\n",
        "            # Save the new best model\n",
        "            model_path = f\"models/best_model_episode_{episode_count}.keras\"\n",
        "            model.save(model_path)\n",
        "            last_saved_model = model_path\n",
        "\n",
        "            # Log the result\n",
        "            with open(log_file, \"a\") as f:\n",
        "                f.write(f\"{episode_count}\\t{running_reward:.2f}\\t{epsilon:.2f}\\n\")\n",
        "\n",
        "            print(f\"New best model saved: {model_path} with running reward: {running_reward:.2f}\")\n",
        "\n",
        "        # Print progress\n",
        "        if episode_count % 10 == 0:\n",
        "            print(f\"Episode {episode_count}, Frame {frame_count}, Running Reward: {running_reward:.2f}, Epsilon: {epsilon:.2f}\")\n",
        "\n",
        "        # Termination conditions\n",
        "        if running_reward > 10000:\n",
        "            print(f\"Solved with a running_reward of {running_reward} at episode {episode_count}!\")\n",
        "            model.save(\"spaceinvaders_qmodel_solved.keras\")\n",
        "            break\n",
        "\n",
        "        if max_episodes > 0 and episode_count >= max_episodes:\n",
        "            print(f\"Stopped at episode {episode_count}!\")\n",
        "            break\n",
        "\n",
        "        if max_frames > 0 and frame_count >= max_frames:\n",
        "            print(f\"Stopped at frame {frame_count}!\")\n",
        "            break\n",
        "\n",
        "    # Final save after training\n",
        "    model.save(\"spaceinvaders_qmodel_final.keras\")\n",
        "    print(\"Final model saved as 'spaceinvaders_qmodel_final.keras'.\")\n",
        "    print(\"Training complete.\")\n",
        "episode_bar.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i_Ge2mEaNvdO",
        "outputId": "7ab7c1a5-1ca6-431e-9d7d-944193cb0e00"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: /GPU:0\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n",
            "state_sample shape before transpose: (32, 4, 84, 84)\n",
            "state_sample shape after transpose: (32, 84, 84, 4)\n",
            "next_state_sample shape before transpose: (32, 4, 84, 84)\n",
            "next_state_sample shape after transpose: (32, 84, 84, 4)\n",
            "state_sample final shape: (32, 84, 84, 4)\n",
            "next_state_sample final shape: (32, 84, 84, 4)\n",
            "action_sample final shape: (32,)\n",
            "Gradient shapes: [TensorShape([8, 8, 4, 32]), TensorShape([32]), TensorShape([4, 4, 32, 64]), TensorShape([64]), TensorShape([3, 3, 64, 64]), TensorShape([64]), TensorShape([3136, 512]), TensorShape([512]), TensorShape([512, 6]), TensorShape([6])]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-ed27f77f1d4e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# Convert to tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mstate_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Combine into a single tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"state_sample shape before transpose:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops_stack.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    711\u001b[0m   \u001b[0;31m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m   \u001b[0mpreferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreferred_dtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m   return tensor_conversion_registry.convert(\n\u001b[0m\u001b[1;32m    714\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccepted_result_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_tensor_conversion.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m   \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    277\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m   const_tensor = ops._create_graph_constant(  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m ) -> ops._EagerTensorBase:\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}